25.7.
To make use of the extensive capabilities of the pi 5, the config tool will be moved to a kivy based UI. This was also done in order to remove any complications that came with drawing to the screen directly instead of using a GUI framework, as well as streamlining the entire software to be more consistent.
The first prototype was still based on the PIL Image being drawn and shown in a Kivy GUI, but this approach was quickly abandoned due to the increased performance of native kivy gui.
Afterwards, a simple GUI was created and the necessary methods are started to get ported over from the old config tool. The seperate dialogues for configuration selection (automatic and manual) were split into their respective screens to streamline navigation.

5.8.
A problem that persisted throughout the prototyping process was the screen for displaying the angles the sensor is reading did not display correctly, mainly with the text label not being displayed. After many itterations, this was fixed by splitting the background and foreground canvas, as well as separating the update mechanics for those. The underlying issue was the clear_canvas() call, which also cleared the label. The reason why it was not rebuild is still partly unknown.
The Angle Display now scales dynamically with the window, giving the user the ability to resize it. 

The logic port of the automatic configuration finished.

Eventually, the table part of the automatic configuration screen was moved to its own class, to be reused with the manual screen.

This was also done with the popup dialogue, which now also accomodates the logic for writing the angles to the database. A small change was made to accomodate custom messages in the initial popup, as the semantics of automatic config confirmation and manual config confirmation change (i.e. just confirm or confirm number of slices).

With these two common elements modularized, the manual config screen was as simple as copying the layout of the automatic config screen, removing the textinput, resizing and relocating the button and changing the logic behind the button press as necessary. Now, with each press of the button, the angle is recorded and shown in the table. When the program detects a similar angle as the first one (i.e. the wheel looped around), the popup dialogue gets called to finish up and commit to database.

6.8.
Ported the kivy file to native python code for the frontend for better visibility with the help of GPT and Claude.
To get moved from the startup screen ("spin wheel") to the topic list screen, a movement detection was necessary. This was promptly implemented into the tlv interface to seperate the logic to where it belongs and make it accessible with a unified API. 
To truly test out the functionality of the frontend and continue the integration, sample data was needed. This was generated using manually collected information from the client's website. Categories were created with the help of AI tools, which the various entries of the data were sorted into. The corresponding importer script was also handled by AI. After a bit of Trial and Error, the function to fetch the necessary data (category, topic titles), based on the current position of the non moving sensor, was finished. Testing this presented the first issue of the buttons not wrapping the text properly, which was then fixed. 

In between all of this, a basic GitHub Project was set up to keep track on the tasks at hand, as well as adding any information for planning/execution to the respective steps.

For a complete workflow, the user would need to be prompted to spin the wheel on startup, which then moves onto a waiting screen to then display the topic list. Whether the user is still browsing topics or reading the description of one, spinning the wheel should always restart this process from the waiting screen. With the current implementation of the movement detection, this was not possible. Thus, the movement detection logic was moved to the parent App class to function as a central controller. The various screens are then able to access the angle read by the sensor via the parent class as well.

7.8.
The content manager application implementation starts. First a draft UI design was made. Following this, the Button Classes from the Frontend were reused in a recylceview of similar construction. For reasons unknown, the buttons did not render correctly. The position of the recycleview itself was correct, but the buttons/recyclelayout were stuck to the bottom left corner. Using database data, the buttons also did not scale correctly. The positioning was fixed by converting the originally Widget class of the ListSelector to be a Recycleview itself. The scaling was fixed by setting an X size hint in the layout and binding the size of the button to the on_size_change function instad of the update_height function. These changes will be backported to the frontend too.
The next, more aethetic issue that arose was the buttons being sorted in alphabetical order instead of numerical order. This was fixed by sorting the input data according to the ID fetched by the database.

Implementing the type selection (categories/topics) proved to be rather difficult. The design requires the user to visually be able to discern, which type was selected at the moment, regardless of the content displayed in the ListSelection. This was eventually achieved using the CompoundSelectionBehaviour and FocusBehavior Class. The necessary method for adding widgets was overwritten and the required events were listened to (button_touch_down, select_node, deselect_node and on_selected_nodes). Communicating the selection then also required certain workarounds to keep a modular and decoupled architecture. In the end, the update of the ListSelection is triggered by a method in the parent ContentManager class, which is called from the MenuBar class via the self.parent statement. MenuBar incorporated parts from a kivy docs example to enable toggleable buttons to visually show which type is selected.


8.8
Continuing with the content manager app, the "editing block" was added, which is supposed to contain the text input fields, as well as the selection to the categories a topic can belong to. Originally, this should've also contained an area for file drag-n-drop but so far it seems like kivy only supports dnd for an entire window, not just certain areas. This will be revised in a future itteration.
For now, the focus lies on the category selector. For this, a numeric property was added to the buttons, which gets the ID from the database object it is supposed to represent assigned. This also (hopefully) lays the groundwork for saving/editing things.
The category selector itself was implemented using a simple scrollview in combination with a stacklayout to enable dynamic scaling of the checkbox areas regardless of text size/length. Methods to load content according to the IDs previously assigned to each button were implemented, as well as a centralized current_data type in the ContentManager parent class. Here, the actual item content loading is triggered from the buttons themselves by getting the content manager from the root window children and calling that function with the ID assigned to the button.
To make things easier, the checkboxes received their own class to combine them with labels. These got, among other, a property for category id, which will be assigned on generation. This enables simple cross-checking with the database, whether a topic belongs to a category, making it simple to already mark it as checked/active. For categories, only the title is loaded as they do not have any other content. Originally it was planned to have a simpler UI for just category editing, but this idea was quickly abandoned due to integration constraints.
